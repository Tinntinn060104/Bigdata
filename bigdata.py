# -*- coding: utf-8 -*-
"""bigdata.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KyrkT4RP9pXLEfZUDg5d2kP7zDReZv2I
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, col, lit
import random

# Initialize Spark session
spark = SparkSession.builder \
    .appName("MovieUserAnalysis") \
    .getOrCreate()

# Step 1: Define genres and movie list
genres = ["Action", "Melody", "Comedy", "Drama", "Romance", "Thriller", "Horror"]
movies = [f"Movie{i}" for i in range(1, 101)]  # Generate 100 movies

# Step 2: Assign one random genre to each movie
movie_genre_map = {movie: random.choice(genres) for movie in movies}

# Convert movie_genre_map to a Spark DataFrame
movie_genre_df = spark.createDataFrame(
    [(movie, genre) for movie, genre in movie_genre_map.items()],
    schema=["movie", "genre"]
)
movie_genre_df.printSchema()
movie_genre_df.show(truncate=False)


# Step 3: Define the number of users and how many movies each user watches
num_users = 20

# Step 4: Generate random data for each user
user_movie_ratings = []
for user_id in range(1, num_users + 1):
    # Each user watches 30 movies (select 30 unique movies randomly from the 100 available)
    watched_movies = random.sample(movies, 30)
    for movie in watched_movies:
        user_movie_ratings.append((user_id, movie, random.randint(1, 5), movie_genre_map[movie]))

# Create a DataFrame for user-movie data
user_movie_df = spark.createDataFrame(
    user_movie_ratings,
    schema=["user_id", "movie", "rating", "genre"]
)

# Print DataFrame Schema and Content
user_movie_df.printSchema()
user_movie_df.show(n = user_movie_df.count(),truncate=False)

# Optional: Function to add null user
def add_null_user(user_id, user_movie_df):
    """
    Adds a null user to the Spark DataFrame.
    """
    # Create a DataFrame for the null user
    null_user_df = spark.createDataFrame([(user_id, None, None, None)], schema=user_movie_df.schema)
    # Union with the existing DataFrame
    updated_df = user_movie_df.union(null_user_df)
    return updated_df

user_movie_df = add_null_user(21, user_movie_df)

from pyspark.sql.functions import avg, col, desc, asc
def show_all_movies(movie_genre_df, user_movie_df):
    """
    Display all movies with their genre and average rating using Spark.
    Resolves ambiguity in column names during join operations.
    """
    # Rename the "movie" column in user_movie_df to avoid ambiguity
    user_movie_df_renamed = user_movie_df.withColumnRenamed("movie", "user_movie")
    user_movie_df_renamed = user_movie_df_renamed.withColumnRenamed("genre", "user_genre")

    # Join movie genre data with user movie data
    movie_ratings_with_genres = movie_genre_df.join(
        user_movie_df_renamed,
        movie_genre_df.movie == user_movie_df_renamed.user_movie,
        how="left"
    )

    # Calculate average rating for each movie
    movie_avg_ratings = movie_ratings_with_genres.groupBy("movie", "genre") \
        .agg(avg("rating").alias("average_rating")) \
        .orderBy(asc("movie"))  # Sort by movie name in descending order

    # Display the result
    print("\nAll Movies with Genre and Average Rating:")
    movie_avg_ratings.select(
        "movie", "genre", col("average_rating").alias("avg_rating")
    ).show(truncate=False)

# Call the function with the Spark DataFrames
show_all_movies(movie_genre_df, user_movie_df)

def show_all_movies(movie_genre_df, user_movie_df):
    """
    Display all movies with their genre and average rating using Spark.
    Resolves ambiguity in column names during join operations.

    Args:
        movie_genre_df (DataFrame): DataFrame containing movie names and genres.
        user_movie_df (DataFrame): DataFrame containing user ratings, movie names, and genres.

    Returns:
        DataFrame: A DataFrame containing movie names, genres, and average ratings.
    """
    # Rename the "movie" column in user_movie_df to avoid ambiguity
    user_movie_df_renamed = user_movie_df.withColumnRenamed("movie", "user_movie")
    user_movie_df_renamed = user_movie_df_renamed.withColumnRenamed("genre", "user_genre")

    # Join movie genre data with user movie data
    movie_ratings_with_genres = movie_genre_df.join(
        user_movie_df_renamed,
        movie_genre_df.movie == user_movie_df_renamed.user_movie,
        how="left"
    )

    # Calculate average rating for each movie
    movie_avg_ratings = movie_ratings_with_genres.groupBy("movie", "genre") \
        .agg(avg("rating").alias("average_rating")) \
        .orderBy(asc("movie"))  # Sort by movie name in ascending order

    # Return the result DataFrame
    all_movie_df = movie_avg_ratings.select(
        "movie", "genre", col("average_rating").alias("avg_rating")
    )

    return all_movie_df

all_movie_df = show_all_movies(movie_genre_df, user_movie_df)

all_movie_df.show(n = all_movie_df.count())

# Add a null user with user_id = 21
user_movie_df = add_null_user(21, user_movie_df)
user_ids_df = user_movie_df.select("user_id").distinct().orderBy("user_id", ascending=True)
user_ids_df.show(n=user_ids_df.count(), truncate=False)

from pyspark.sql import DataFrame, functions as F

def map_ratings(df: DataFrame, preferred_genres: list) -> DataFrame:
    """
    Map phase: Filters movies by preferred genres and groups by movie.

    Args:
        df (DataFrame): Input DataFrame with columns [user_id, movie, rating, genre].
        preferred_genres (list): List of genres to filter.

    Returns:
        DataFrame: A DataFrame grouped by movie with aggregated user ratings.
    """
    # Filter for preferred genres
    filtered_df = df.filter(F.col("genre").isin(preferred_genres))

    # Filter for movies with null genres
    null_movie_df = df.filter(F.col("genre").isNull())

    # Union the filtered movies with preferred genres and null genre movies
    filtered_df = filtered_df.union(null_movie_df)
    # Group by movie and collect user-rating pairs
    mapped_df = filtered_df.groupBy("movie").agg(
        F.collect_list(F.struct("user_id", "rating", "genre")).alias("user_ratings")
    )
    return mapped_df

def reduce_ratings(mapped_df: DataFrame, all_movies_df: DataFrame, preferred_genres: list) -> DataFrame:
    """
    Reduce phase: Generates movie recommendations based on user pairs and handles users who haven't watched any movies.

    Args:
        mapped_df (DataFrame): A DataFrame with columns [movie, user_ratings].
        all_movies_df (DataFrame): A DataFrame of all movies with columns [movie, genre, avg_rating].
        preferred_genres (list): List of genres to filter.

    Returns:
        DataFrame: A DataFrame with recommended movies for each user.
    """
    # Explode the user_ratings array for pairwise processing
    exploded_df = mapped_df.select(
        F.col("movie"),
        F.explode("user_ratings").alias("user_rating")
    )
    # Create pairwise combinations of users who rated the same movie

    user_pairs_df = (
        exploded_df.alias("df1")
        .join(
            exploded_df.alias("df2"),
            (F.col("df1.movie") == F.col("df2.movie")) &
            (F.col("df1.user_rating.user_id") <= F.col("df2.user_rating.user_id"))
        )
        .select(
            F.col("df1.user_rating.user_id").alias("user1"),
            F.col("df2.user_rating.user_id").alias("user2"),
            F.col("df1.movie"),
            F.col("df1.user_rating.rating").alias("rating1"),
            F.col("df2.user_rating.rating").alias("rating2"),
            F.col("df1.user_rating.genre").alias("genre")
        )
    )

    # Aggregate recommendations for users based on movies they've watched
    recommendations_df = (
        user_pairs_df.groupBy("user1")
        .agg(F.collect_set("movie").alias("recommended_movies"))
    )
    # Handle users who haven't watched any movies
    all_users_df = exploded_df.select(F.col("user_rating.user_id").alias("user_id")).distinct()
    watched_users_df = recommendations_df.select(F.col("user1").alias("user_id")).distinct()

    non_watched_users_df = all_users_df.join(watched_users_df, "user_id", "left_anti")

    # Recommend movies with preferred genres and high average ratings to non-watched users
    high_avg_rating_movies_df = all_movies_df.filter(
        (F.col("genre").isin(preferred_genres)) & (F.col("avg_rating") > 4)
    ).select("movie")

    non_watched_recommendations_df = non_watched_users_df.crossJoin(
        high_avg_rating_movies_df
    ).groupBy("user_id").agg(F.collect_set("movie").alias("recommended_movies"))

    # Combine recommendations for all users, ensuring all users are included
    final_recommendations_df = recommendations_df.select(
        F.col("user1").alias("user_id"), "recommended_movies"
    ).unionByName(non_watched_recommendations_df)

    return final_recommendations_df

# Define preferred genres
preferred_genres = ["Action", "Thriller"]
# Step 1: Apply the map function
mapped_df= map_ratings(user_movie_df, preferred_genres)
# Step 2: Apply the reduce function
recommendations_df = reduce_ratings(mapped_df ,all_movie_df,preferred_genres)
# Show the results
recommendations_df.show(n= recommendations_df.count(),truncate=False)